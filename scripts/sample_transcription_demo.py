#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ColabVideoTranscriber
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
"""

import json
from datetime import datetime

def create_sample_transcription():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞"""
    
    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
    sample_data = {
        "video_info": {
            "title": "–†–∏–∫ –∏ –ú–æ—Ä—Ç–∏ S01E01 - –ü–∏–ª–æ—Ç",
            "file_size": "125.3 MB",
            "duration": "1234.5 —Å–µ–∫",
            "model_used": "base",
            "processed_at": "2024-01-15T10:30:00"
        },
        "transcription": {
            "language": "ru",
            "segments": [
                {
                    "start": 0.0,
                    "end": 3.523,
                    "text": "–ü—Ä–∏–≤–µ—Ç, –ú–æ—Ä—Ç–∏! –ü–æ—à–ª–∏ –≤ –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏–µ!",
                    "words": [
                        {"start": 0.0, "end": 0.847, "word": "–ü—Ä–∏–≤–µ—Ç", "probability": 0.95},
                        {"start": 0.847, "end": 1.156, "word": ",", "probability": 0.99},
                        {"start": 1.156, "end": 2.034, "word": "–ú–æ—Ä—Ç–∏", "probability": 0.98},
                        {"start": 2.034, "end": 2.234, "word": "!", "probability": 0.99},
                        {"start": 2.234, "end": 2.456, "word": " ", "probability": 0.99},
                        {"start": 2.456, "end": 3.012, "word": "–ü–æ—à–ª–∏", "probability": 0.94},
                        {"start": 3.012, "end": 3.234, "word": " ", "probability": 0.99},
                        {"start": 3.234, "end": 3.456, "word": "–≤", "probability": 0.97},
                        {"start": 3.456, "end": 3.523, "word": "–ø—Ä–∏–∫–ª—é—á–µ–Ω–∏–µ!", "probability": 0.96}
                    ]
                },
                {
                    "start": 3.523,
                    "end": 8.234,
                    "text": "–†–∏–∫, —Ç—ã —Å–æ—à—ë–ª —Å —É–º–∞! –ú—ã –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –≤–∑–æ—Ä–≤–∞—Ç—å –ø–ª–∞–Ω–µ—Ç—É!",
                    "words": [
                        {"start": 3.523, "end": 4.012, "word": "–†–∏–∫", "probability": 0.98},
                        {"start": 4.012, "end": 4.234, "word": ",", "probability": 0.99},
                        {"start": 4.234, "end": 4.456, "word": " ", "probability": 0.99},
                        {"start": 4.456, "end": 4.789, "word": "—Ç—ã", "probability": 0.97},
                        {"start": 4.789, "end": 5.234, "word": "—Å–æ—à—ë–ª", "probability": 0.95},
                        {"start": 5.234, "end": 5.456, "word": " ", "probability": 0.99},
                        {"start": 5.456, "end": 5.678, "word": "—Å", "probability": 0.98},
                        {"start": 5.678, "end": 6.012, "word": "—É–º–∞", "probability": 0.96},
                        {"start": 6.012, "end": 6.234, "word": "!", "probability": 0.99},
                        {"start": 6.234, "end": 6.456, "word": " ", "probability": 0.99},
                        {"start": 6.456, "end": 6.789, "word": "–ú—ã", "probability": 0.97},
                        {"start": 6.789, "end": 7.012, "word": " ", "probability": 0.99},
                        {"start": 7.012, "end": 7.345, "word": "–Ω–µ", "probability": 0.98},
                        {"start": 7.345, "end": 7.678, "word": "–º–æ–∂–µ–º", "probability": 0.95},
                        {"start": 7.678, "end": 7.890, "word": " ", "probability": 0.99},
                        {"start": 7.890, "end": 8.123, "word": "–ø—Ä–æ—Å—Ç–æ", "probability": 0.94},
                        {"start": 8.123, "end": 8.234, "word": "–≤–∑–æ—Ä–≤–∞—Ç—å –ø–ª–∞–Ω–µ—Ç—É!", "probability": 0.93}
                    ]
                },
                {
                    "start": 8.234,
                    "end": 12.845,
                    "text": "–ú–æ—Ä—Ç–∏, —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø–ª–∞–Ω–µ—Ç–∞. –≠—Ç–æ –Ω–æ–≤—ã–π –º–∏—Ä, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Å–æ–∑–¥–∞–¥–∏–º!",
                    "words": [
                        {"start": 8.234, "end": 8.678, "word": "–ú–æ—Ä—Ç–∏", "probability": 0.98},
                        {"start": 8.678, "end": 8.890, "word": ",", "probability": 0.99},
                        {"start": 8.890, "end": 9.123, "word": " ", "probability": 0.99},
                        {"start": 9.123, "end": 9.456, "word": "—ç—Ç–æ", "probability": 0.97},
                        {"start": 9.456, "end": 9.678, "word": " ", "probability": 0.99},
                        {"start": 9.678, "end": 10.012, "word": "–Ω–µ", "probability": 0.98},
                        {"start": 10.012, "end": 10.345, "word": "–ø—Ä–æ—Å—Ç–æ", "probability": 0.96},
                        {"start": 10.345, "end": 10.678, "word": "–ø–ª–∞–Ω–µ—Ç–∞", "probability": 0.95},
                        {"start": 10.678, "end": 10.890, "word": ".", "probability": 0.99},
                        {"start": 10.890, "end": 11.123, "word": " ", "probability": 0.99},
                        {"start": 11.123, "end": 11.456, "word": "–≠—Ç–æ", "probability": 0.97},
                        {"start": 11.456, "end": 11.789, "word": "–Ω–æ–≤—ã–π", "probability": 0.96},
                        {"start": 11.789, "end": 12.123, "word": "–º–∏—Ä", "probability": 0.95},
                        {"start": 12.123, "end": 12.456, "word": ",", "probability": 0.99},
                        {"start": 12.456, "end": 12.678, "word": " ", "probability": 0.99},
                        {"start": 12.678, "end": 12.845, "word": "–∫–æ—Ç–æ—Ä—ã–π –º—ã —Å–æ–∑–¥–∞–¥–∏–º!", "probability": 0.94}
                    ]
                }
            ]
        }
    }
    
    return sample_data

def save_sample_files():
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–æ–≤"""
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤
    import os
    os.makedirs("data/sample_output", exist_ok=True)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    sample_data = create_sample_transcription()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Ñ–∞–π–ª
    json_path = "data/sample_output/sample_transcription.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –ü—Ä–∏–º–µ—Ä JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_path}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    text_path = "data/sample_output/sample_transcription.txt"
    with open(text_path, 'w', encoding='utf-8') as f:
        f.write("–¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø –í–ò–î–ï–û\n")
        f.write("=" * 50 + "\n\n")
        
        f.write("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –í–ò–î–ï–û:\n")
        for key, value in sample_data["video_info"].items():
            f.write(f"{key}: {value}\n")
        f.write("\n")
        
        f.write("–¢–ï–ö–°–¢:\n")
        f.write("-" * 30 + "\n")
        
        for segment in sample_data["transcription"]["segments"]:
            start_time = format_time(segment["start"])
            end_time = format_time(segment["end"])
            f.write(f"[{start_time} - {end_time}] {segment['text']}\n")
    
    print(f"‚úÖ –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {text_path}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è GPT
    compact_data = {
        "segments": [
            {
                "time": f"{segment['start']:.3f}-{segment['end']:.3f}s",
                "text": segment["text"]
            }
            for segment in sample_data["transcription"]["segments"]
        ]
    }
    
    compact_path = "data/sample_output/sample_compact.json"
    with open(compact_path, 'w', encoding='utf-8') as f:
        json.dump(compact_data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {compact_path}")
    
    return json_path, text_path, compact_path

def format_time(seconds):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –≤ HH:MM:SS.mmm"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}.{milliseconds:03d}"

def show_usage_examples():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    
    print("üìã –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–ò")
    print("=" * 50)
    
    print("\n1. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤:")
    print("   - –ù–∞–π–¥–∏—Ç–µ –≤—Å–µ —Ä–µ–ø–ª–∏–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞")
    print("   - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
    print("   - –°–æ–∑–¥–∞–π—Ç–µ —Å—É–±—Ç–∏—Ç—Ä—ã —Å —Ç–æ—á–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏")
    
    print("\n2. –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞:")
    print("   - –ù–∞–π–¥–∏—Ç–µ —Å–∞–º—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã")
    print("   - –°–æ–∑–¥–∞–π—Ç–µ –∫–ª–∏–ø—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º")
    print("   - –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è YouTube")
    
    print("\n3. –î–ª—è –æ–±—É—á–µ–Ω–∏—è GPT:")
    print("   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤")
    print("   - –í–∫–ª—é—á–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã")
    print("   - –î–æ–±–∞–≤–ª—è–π—Ç–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞—Ö –∏ —Å—é–∂–µ—Ç–µ")
    
    print("\n4. –î–ª—è –ø–æ–∏—Å–∫–∞:")
    print("   - –ù–∞–π–¥–∏—Ç–µ —Ñ—Ä–∞–∑—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º")
    print("   - –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –≤—Ä–µ–º—è –ø–æ—è–≤–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π")
    print("   - –°–æ–∑–¥–∞–π—Ç–µ –∏–Ω–¥–µ–∫—Å –≤–∞–∂–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤")

if __name__ == "__main__":
    print("üé¨ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª—ã
    json_path, text_path, compact_path = save_sample_files()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    show_usage_examples()
    
    print(f"\nüìÅ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: data/sample_output/")
    print(f"üìÑ JSON —Ñ–∞–π–ª: {json_path}")
    print(f"üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {text_path}")
    print(f"üìÑ –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–∞–π–ª: {compact_path}")
    
    print("\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –≤—ã–≤–æ–¥–∞!")
